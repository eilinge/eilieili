user  nginx;
worker_processes  2;
worker_rlimit_nofile 1024;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
    multi_accept on;
    use epoll;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    # access_log  /var/log/nginx/access.log  main;
    # error_log /var/log/nginx/error.log;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    server_tokens;

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;# Dropping SSLv3, ref: POODLE
    ssl_prefer_server_ciphers on;

    gzip  on;
    gzip_disable "msie6";

    include /etc/nginx/conf.d/*.conf;

    server {
        listen 80;
        server_name localhost 192.168.212.133;
        root /nginx/www;
        index index.php index.html;
        charset utf-8;
        # access_log logs/access.log;
        # error_log logs/error.log;

        location / {
            root /nginx/www;
            index index.php index.html;

            #通过反向代理代理服务器访问模式, 通过proxy_set配置让客户端访问透明化
			proxy_pass http://localhost:8888;
            proxy_set_header X-real-ip $remote_addr;
            proxy_set_header Host $http_host;

            # 如果不用nginx一样可以访问web项目, 使用nginx的目的是为了安全和负载均衡。配置了nginx做前端代理, 
            # uwsgi作后端代理的服务器(这里所说的前后端都是相对的位置, 并无实际含义), 在处理来自Internet的请求时, 
            # 要先经过nginx的处理, nginx把请求再交给uwsgi, 经过uwsgi才能访问到项目本身

            # nginx的作用：
            # 1.反向代理, 可以拦截一些web攻击, 保护后端的web服务器
            # 2.负载均衡, 根据轮询算法, 分配请求到多节点web服务器
            # 3.缓存静态资源, 加快访问速度, 释放web服务器的内存占用, 专项专用

            # uWSGI的适用：
            # 1.单节点服务器的简易部署
            # 2.轻量级, 好部署

            #uwsgi模式下的服务器配置访问方式
			include uwsgi_params;
            uwsgi_pass localhost:8888;
        }
    }
    # 例子中,  设置了三台后台服务器, 所占的比重分别为5, 3, 1。 那么如何做到在收到请求的时候,  
    # 按照比例分配到后台的三台服务器呢。 能想到的最简单的方法当然是：如果当前权重大于0, 
    # 就发往这台服务器, 然后权重减1,  但是这种方法分发的请求结果就是[a,a,a,a,a,b,b,b,c],  
    # 虽然达到了目标的比例, 但是有一段时间请求都发往了a,  另一段都发往了b, 这显然不是一种好的处理方式, 
    # 对每台机器来说相当于忙一阵, 闲一阵, 并没有平均的收到请求。

    # 那么nginx中是如何来做负载均衡, 让每台机器收到的请求频率更为平均--weighted round robin (WRR)的算法

    upstream backserver { 
        server 192.168.212.133:8000 weight=5;
        server 192.168.212.133:8001 weight=3;
        server 192.168.212.133:8002 weight=3;
    } 
}